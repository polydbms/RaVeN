from pyspark.sql import SparkSession
from sedona.register import SedonaRegistrator
from sedona.core.formatMapper.shapefileParser import ShapefileReader
from sedona.utils.adapter import Adapter
from sedona.core.enums import GridType
from sedona.core.enums import IndexType
from sedona.utils import SedonaKryoRegistrator, KryoSerializer
from pathlib import Path
import uuid
import shutil

spark = SparkSession.\
    builder.\
    master("local[*]").\
    appName("Sedona App").\
    config("spark.serializer", KryoSerializer.getName).\
    config("spark.kryo.registrator", SedonaKryoRegistrator.getName) .\
    config('spark.jars.packages',
           'org.apache.sedona:sedona-python-adapter-3.0_2.12:1.1.1-incubating,'
           'org.datasyslab:geotools-wrapper:1.1.0-25.2'). \
    getOrCreate()
SedonaRegistrator.registerAll(spark)
sc = spark.sparkContext

vector_table = "{{vector_name}}"
raster_table = "{{raster_name}}"
{{vector_name}} = ShapefileReader.readToGeometryRDD(sc, "{{vector_path}}")
{{vector_name}}.analyze()
{{vector_name}}.spatialPartitioning(GridType.KDBTREE)
{{vector_name}}.buildIndex(IndexType.RTREE, True)
{{vector_name}}_df = Adapter.toDf({{vector_name}}, spark).repartition(1000).createOrReplaceTempView(vector_table)

{{raster_name}} = ShapefileReader.readToPolygonRDD(sc, "{{raster_path}}")
{{raster_name}}.analyze()
{{raster_name}}.spatialPartitioning({{vector_name}}.getPartitioner())
{{raster_name}}.buildIndex(IndexType.RTREE, True)
{{raster_name}}_df = Adapter.toDf({{raster_name}}, spark).repartition(1000).createOrReplaceTempView(raster_table)

spatial_gdf = spark.sql(
                        """
                        {{query}}
                        """
                       )

name = uuid.uuid4().hex
spatial_gdf.coalesce(1).write.option("header","true").csv(name)
[a for a in Path(name).glob("*.csv")][0].rename("results.csv")
shutil.move("results.csv", "/data/results_sedona.csv")